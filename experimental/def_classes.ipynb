{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías para los sistemas de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "from surprise import ( \n",
    "  Dataset,\n",
    "  Reader,\n",
    "  accuracy, \n",
    "  SVD,\n",
    "  AlgoBase,\n",
    "  BaselineOnly\n",
    ") \n",
    "\n",
    "from surprise.model_selection import (\n",
    "  train_test_split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `DataLoader`\n",
    "\n",
    "La clase `DataLoader` está diseñada para cargar y manipular datos relacionados para un sistema de recomendación. A continuación se detalla su funcionalidad:\n",
    "\n",
    "- Constructor (`__init__`)\n",
    "  - Inicializa la instancia con tres argumentos que representan las rutas de acceso a los archivos de datos de usuarios, items y datos de interacción (ratings). Construye las rutas completas combinándolas con la ruta actual del directorio de trabajo del sistema operativo\n",
    "  - Carga automáticamente los conjuntos de datos para usuarios, items y datos de interacción (ratings) utilizando el método `load_set`\n",
    "- Método `load_set`\n",
    "  - Recibe como argumento `name` que indica qué conjunto de datos cargar ( 'DATA', 'USER', 'ITEM' )\n",
    "  - Dependiendo del valor de `name`, carga un DataFrame correspondiente desde un archivo CSV, especificando las columnas esperadas y ajustando el separador y la codificación según sea necesario\n",
    "  - Para los conjuntos de datos 'DATA' y 'USER', elimina columnas no deseadas después de la carga\n",
    "  - Para el conjunto de datos 'ITEM', también elimina columnas específicas no necesarias\n",
    "- Método `load_dataset`\n",
    "  - Crea un objeto `Dataset` de la biblioteca `surprise` a partir del conjunto de datos de interacción cargado previamente, preparándolo para su uso en modelos de recomendación.\n",
    "  - Configura el `Reader` para interpretar las escalas de calificación de los ratings.\n",
    "- Métodos de consulta\n",
    "  - `get_user_by_id`: Busca información de un usuario por su ID, devolviendo un diccionario con detalles del usuario.\n",
    "  - `get_item_by_id`: Busca información de un ítem por su ID, devolviendo un diccionario con detalles del ítem.\n",
    "  - `get_rating_by_ids`: Intenta encontrar el rating dado un ID de usuario e ID de ítem, devolviendo el rating junto con un indicador de éxito (True si se encontró, False en caso contrario).\n",
    "  - `get_ratings_by_name_id`: Filtra los datos de interacción para encontrar ratings basados en un criterio específico (por ejemplo, ID de género), devolviendo un DataFrame con los ratings encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader: \n",
    "  \n",
    "  def __init__(self, data_path: str, item_path: str, user_path: str) -> None:\n",
    "    \n",
    "    current = os.getcwd () [ 0 : os.getcwd ().rfind( '\\\\' ) ]\n",
    "    self.DATA_PATH = current + data_path\n",
    "    self.ITEM_PATH = current + item_path\n",
    "    self.USER_PATH = current + user_path\n",
    "\n",
    "    self.data_set = self.load_set ( 'DATA' )\n",
    "    self.item_set = self.load_set ( 'ITEM' )\n",
    "    self.user_set = self.load_set ( 'USER' )\n",
    "\n",
    "  def load_set (self, name: str ) -> pd.DataFrame:\n",
    "\n",
    "    if name == 'DATA':\n",
    "      columns = [ 'userID', 'itemID', 'rating', 'timestamp' ]\n",
    "      df = pd.read_csv ( \n",
    "        self.DATA_PATH, \n",
    "        names=columns, \n",
    "        sep='\\t', \n",
    "        encoding='latin-1', \n",
    "        skipinitialspace=True \n",
    "      )\n",
    "      df = df.drop ( columns= [ 'timestamp' ] )\n",
    "      return df\n",
    "  \n",
    "    if name == 'USER':\n",
    "      columns = [ 'userID', 'age', 'gender', 'occupation', 'zipCode' ]\n",
    "      df = pd.read_csv ( \n",
    "        self.USER_PATH, \n",
    "        names=columns, \n",
    "        sep='|', \n",
    "        encoding='latin-1', \n",
    "        skipinitialspace=True \n",
    "      )\n",
    "      df = df.drop ( columns= [ 'zipCode' ] )\n",
    "      return df\n",
    "  \n",
    "    if name == 'ITEM':\n",
    "      columns = [ \n",
    "        'itemID', \n",
    "        'name', \n",
    "        'releaseDate', \n",
    "        'videoReleaseDate', \n",
    "        'IMDbURL', \n",
    "        'gender_unknown', \n",
    "        'gender_action', \n",
    "        'gender_adventure', \n",
    "        'gender_animation', \n",
    "        'gender_children', \n",
    "        'gender_comedy',\n",
    "        'gender_crime',\n",
    "        'gender_documentary',\n",
    "        'gender_drama',\n",
    "        'gender_fantasy',\n",
    "        'gender_film_noir',\n",
    "        'gender_horror',\n",
    "        'gender_musical',\n",
    "        'gender_mystery',\n",
    "        'gender_romance',\n",
    "        'gender_scifi',\n",
    "        'gender_thriller',\n",
    "        'gender_war',\n",
    "        'gender_western',\n",
    "      ]\n",
    "      df = pd.read_csv ( \n",
    "        self.ITEM_PATH, \n",
    "        names=columns, \n",
    "        sep='|', \n",
    "        encoding='latin-1', \n",
    "        skipinitialspace=True \n",
    "      )\n",
    "      df = df.drop ( columns= [ 'videoReleaseDate', 'IMDbURL' ] )\n",
    "      return df\n",
    "\n",
    "  def load_dataset ( self ) -> Dataset:\n",
    "    reader = Reader ( rating_scale= ( 1,5 ) )\n",
    "    data = Dataset.load_from_df ( self.data_set [ [ 'userID', 'itemID', 'rating' ] ], reader )\n",
    "    return data\n",
    "\n",
    "  def get_user_by_id ( self, id: int ):\n",
    "    info = self.user_set.loc [ self.user_set[ 'userID' ] == id ]\n",
    "    return info[ [ 'userID', 'age', 'gender', 'occupation' ] ].iloc[0].to_dict()\n",
    "\n",
    "  def get_item_by_id ( self, id: int ):\n",
    "    info = self.item_set.loc [ self.item_set[ 'itemID' ] == id ]\n",
    "    return info[ [ \n",
    "      'itemID', \n",
    "      'name', \n",
    "      'releaseDate', \n",
    "      'gender_unknown', \n",
    "      'gender_action', \n",
    "      'gender_adventure', \n",
    "      'gender_animation', \n",
    "      'gender_children', \n",
    "      'gender_comedy',\n",
    "      'gender_crime',\n",
    "      'gender_documentary',\n",
    "      'gender_drama',\n",
    "      'gender_fantasy',\n",
    "      'gender_film_noir',\n",
    "      'gender_horror',\n",
    "      'gender_musical',\n",
    "      'gender_mystery',\n",
    "      'gender_romance',\n",
    "      'gender_scifi',\n",
    "      'gender_thriller',\n",
    "      'gender_war',\n",
    "      'gender_western', ] ].iloc[0].to_dict()\n",
    "\n",
    "  def get_rating_by_ids ( self, user_id: int, item_id: int ):\n",
    "    try:\n",
    "      rating = self.data_set.loc [ self.data_set[ 'userID' ] == user_id ].loc [ self.data_set[ 'itemID' ] == item_id ]\n",
    "      return ( rating.iloc[0]['rating'], True )\n",
    "    except:\n",
    "      # Failed to retrieve the rating\n",
    "      return ( -1, False )\n",
    "\n",
    "  def get_ratings_by_name_id ( self, column_name: str, id: int ):\n",
    "    filtered_data = self.data_set.loc [ self.data_set[ column_name ] == id ]\n",
    "    return filtered_data [ [ 'userID', 'itemID', 'rating' ] ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las direcciones donde tienen los datos para el sistema de recomendación son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '\\\\dataset\\\\data.csv'\n",
    "ITEM_PATH = '\\\\dataset\\\\item.csv'\n",
    "USER_PATH = '\\\\dataset\\\\user.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader( \n",
    "  data_path=DATA_PATH,\n",
    "  item_path=ITEM_PATH,\n",
    "  user_path=USER_PATH \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  itemID  rating\n",
       "0         196     242       3\n",
       "1         186     302       3\n",
       "2          22     377       1\n",
       "3         244      51       2\n",
       "4         166     346       1\n",
       "...       ...     ...     ...\n",
       "99995     880     476       3\n",
       "99996     716     204       5\n",
       "99997     276    1090       1\n",
       "99998      13     225       2\n",
       "99999      12     203       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.data_set\n",
    "#loader.item_set\n",
    "#loader.user_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "\n",
      "Results Dataframe sort values by item id\n",
      "       userID  itemID  rating\n",
      "17102     196       8       5\n",
      "56628     196      13       2\n",
      "10981     196      25       4\n",
      "22271     196      66       3\n",
      "2374      196      67       5\n",
      "21605     196      70       3\n",
      "14606     196      94       3\n",
      "23189     196     108       4\n",
      "87863     196     110       1\n",
      "10017     196     111       4\n",
      "33536     196     116       3\n",
      "52726     196     153       5\n",
      "59607     196     173       2\n",
      "24030     196     202       3\n",
      "7517      196     238       4\n",
      "0         196     242       3\n",
      "1812      196     251       3\n",
      "22773     196     257       2\n",
      "78787     196     269       3\n",
      "36281     196     285       5\n",
      "13733     196     286       5\n",
      "32721     196     287       3\n",
      "6910      196     306       4\n",
      "25726     196     340       3\n",
      "1133      196     381       4\n",
      "35197     196     382       4\n",
      "940       196     393       4\n",
      "50147     196     411       4\n",
      "17830     196     428       4\n",
      "10254     196     580       2\n",
      "1896      196     655       5\n",
      "7842      196     663       5\n",
      "16834     196     692       5\n",
      "59165     196     762       3\n",
      "60706     196     845       4\n",
      "42384     196    1007       4\n",
      "60199     196    1022       4\n",
      "18853     196    1118       4\n",
      "41539     196    1241       3\n",
      "\n",
      "========================================\n",
      "\n",
      "Results Dataframe sort values by rating\n",
      "       userID  itemID  rating\n",
      "36281     196     285       5\n",
      "16834     196     692       5\n",
      "1896      196     655       5\n",
      "2374      196      67       5\n",
      "52726     196     153       5\n",
      "7842      196     663       5\n",
      "13733     196     286       5\n",
      "17102     196       8       5\n",
      "42384     196    1007       4\n",
      "50147     196     411       4\n",
      "23189     196     108       4\n",
      "940       196     393       4\n",
      "18853     196    1118       4\n",
      "17830     196     428       4\n",
      "60199     196    1022       4\n",
      "35197     196     382       4\n",
      "10981     196      25       4\n",
      "60706     196     845       4\n",
      "10017     196     111       4\n",
      "7517      196     238       4\n",
      "6910      196     306       4\n",
      "1133      196     381       4\n",
      "59165     196     762       3\n",
      "78787     196     269       3\n",
      "41539     196    1241       3\n",
      "0         196     242       3\n",
      "22271     196      66       3\n",
      "33536     196     116       3\n",
      "32721     196     287       3\n",
      "25726     196     340       3\n",
      "24030     196     202       3\n",
      "21605     196      70       3\n",
      "14606     196      94       3\n",
      "1812      196     251       3\n",
      "22773     196     257       2\n",
      "56628     196      13       2\n",
      "59607     196     173       2\n",
      "10254     196     580       2\n",
      "87863     196     110       1\n",
      "\n",
      "========================================\n",
      "\n",
      "Shape: (39, 3)\n",
      "\n",
      "\n",
      "Rating: (3, True)\n",
      "{'itemID': 242, 'name': 'Kolya (1996)', 'releaseDate': '24-Jan-1997', 'gender_unknown': 0, 'gender_action': 0, 'gender_adventure': 0, 'gender_animation': 0, 'gender_children': 0, 'gender_comedy': 1, 'gender_crime': 0, 'gender_documentary': 0, 'gender_drama': 0, 'gender_fantasy': 0, 'gender_film_noir': 0, 'gender_horror': 0, 'gender_musical': 0, 'gender_mystery': 0, 'gender_romance': 0, 'gender_scifi': 0, 'gender_thriller': 0, 'gender_war': 0, 'gender_western': 0}\n",
      "{'userID': 196, 'age': 49, 'gender': 'M', 'occupation': 'writer'}\n"
     ]
    }
   ],
   "source": [
    "ratings_by_user_id = loader.get_ratings_by_name_id ( column_name='userID', id=196 )\n",
    "\n",
    "results = f\"\"\"\n",
    "========================================\n",
    "\n",
    "Results Dataframe sort values by item id\n",
    "{ ratings_by_user_id.sort_values ( by='itemID', ascending=True ) }\n",
    "\n",
    "========================================\n",
    "\n",
    "Results Dataframe sort values by rating\n",
    "{ ratings_by_user_id.sort_values ( by='rating', ascending=False ) }\n",
    "\n",
    "========================================\n",
    "\n",
    "Shape: { ratings_by_user_id.shape }\n",
    "\n",
    "\"\"\"\n",
    "print ( results )\n",
    "\n",
    "rating_by_ids = loader.get_rating_by_ids ( item_id=242, user_id=196 )\n",
    "print ( f'Rating: { rating_by_ids }' )\n",
    "\n",
    "info_item = loader.get_item_by_id ( id=242 )\n",
    "print ( info_item )\n",
    "\n",
    "info_user = loader.get_user_by_id ( id=196 )\n",
    "print ( info_user )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `Exploratory_Data_Analysis`\n",
    "\n",
    "El Análisis Exploratorio de Datos permite determinar la mejor manera de manipular lsa fuentes de datos para obtener las respuesta que necesita, permitiendo descubrir patrones, detectar anomalías, probar una hipótesis o verificar suposiciones. \n",
    "\n",
    "El objetivo de tener una clase para el Análisis Exploratorio de Datos es ayudar a analizar los datos antes de hacer las predicciones. Permitiendo en algunos casos identificar errores obvios, así como comprender mejor los patrones dentro de los datos e incluso encontrar relaciones interesantes entre las variables. \n",
    "\n",
    "Herramientas que pudieran usarse para el Análisis Exploratorio de Datos: \n",
    "- Técnicas de clustering y reducción de dimensiones\n",
    "- Visualización univariante de cada campo del conjunto de datos sin procesar, con estadísticas de resumen\n",
    "- Visualización bivariante y estadísticas de resumen que le permiten evaluar la relación entre cada variable del conjunto de datos y la variable de destino que está viendo\n",
    "- Visualización multivariantes, para mapear y comprender las interacciones entre los diferentes campos de datos \n",
    "- Métodos predictivos como la regresión lineal permite la predicción de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exploratory_Data_Analysis: \n",
    "  pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `Metrics`\n",
    "\n",
    "La clase `Metrics` está diseñada para calcular y almacenar métricas de evaluación comunes en proyectos de sistemas de recomendación. \n",
    "\n",
    "- Constructor (`__init__`)\n",
    "  - Inicializa la instancia con un argumento `predictions`, que representa las predicciones generadas por un modelo de recomendación\n",
    "  - Inicializa un diccionario `metrics` vacío para almacenar los resultados de las métricas calculadas \n",
    "- Método `compute_metrics`\n",
    "  - Permite calcular múltiples métricas de evaluación a la vez, pasando los nombres de las métricas como argumentos\n",
    "  - Actualiza el diccionario `metrics` con los valores calculados para las métricas solicitadas\n",
    "  - Retorna el diccionario `metrics` actualizado\n",
    "- Método de Métricas\n",
    "  - `MAE`: abreviatura de Mean Absolute Error, y calcula el Error Absoluto Medio entre las predicciones y los valores reales. Este método actualiza el diccionario `metrics` con el valor de MAE calculado.\n",
    "  - `RMSE`: abreviatura de Root Mean Square Error, y calcula el Error Cuadrático Medio Raíz entre las predicciones y los valores reales. Este método actualiza el diccionario `metrics` con el valor de RMSE calculado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics: \n",
    "  def __init__(self, predictions) -> None:\n",
    "    self.predictions = predictions\n",
    "    self.metrics = { }\n",
    "\n",
    "  def compute_metrics ( self, *args ) -> dict :\n",
    "    if 'MAE' in args: self.MAE ( )\n",
    "    if 'RMSE' in args: self.RMSE ( )\n",
    "    return self.metrics\n",
    "\n",
    "  def MAE  ( self ):\n",
    "    self.metrics [ 'MAE' ] = accuracy.mae ( self.predictions ) \n",
    "\n",
    "  def RMSE ( self ): \n",
    "    self.metrics [ 'RMSE' ] = accuracy.rmse ( self.predictions ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `DataGenerator`\n",
    "\n",
    "La clase `DataGenerator` está diseñada para facilitar la división de un conjunto de datos en subconjuntos de entrenamiento y prueba, lo cual es una tarea común en el desarrollo y evaluación de modelos de Machine Learning y Sistemas de Recomendación. A continuación, se detalla su funcionalidad:\n",
    "- Constructor (`__init__`)\n",
    "  - `data`: conjunto de datos general que se desea dividir en entrenamiento y prueba\n",
    "  - `percentage`: un valor opcional que especifica el tamaño del subconjunto de prueba como un porcentaje del total de datos. Por defecto este valor es 0.25, lo que significa que el 25% de los datos se reservará para el conjunto de prueba, dejando el 75% para el conjunto de entrenamiento\n",
    "  - Utiliza la función `train_test_split` de scikit-learn para dividir el conjunto de datos en entrenamiento y prueba basándose en el tamaño especificado por `percentage`. Se establece un estado aleatorio fijo (`random_state = 1`) para garantizar la reproducibilidad de la división\n",
    "  - Guarda los subconjuntos resultantes en los atributos `self.trainset` y `self.testset`\n",
    "- Métodos \n",
    "  - `get_trainset`: Retorna el subconjunto de datos designado para entrenamiento\n",
    "  - `get_testset`: Retorna el subconjunto de datos designado para prueba\n",
    "\n",
    "La clase `DataGenerator` automatiza el proceso de preparación de los datos para el entrenamiento y la evaluación de modelos de Machine Learning. Al instanciar `DataGenerator` con un conjunto de datos y un porcentaje para la división de prueba, se genera automáticamente una partición de los datos en conjuntos de entrenamiento y prueba, facilitando la evaluación de modelos sin tener que repetir manualmente el proceso de división cada vez que se necesita entrenar o probar un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator: \n",
    "  def __init__(self, data, percentage = 0.25) -> None:\n",
    "    \"\"\"Data Generator\n",
    "\n",
    "    Build a 75/25 train/test split for measuring accuracy\n",
    "\n",
    "    Args:\n",
    "        percentage (float, optional): _description_. Defaults to 0.25.\n",
    "    \"\"\"\n",
    "    self.trainset, self.testset = train_test_split ( data, test_size=percentage, random_state=1 )\n",
    "\n",
    "# MEJORAR CON UN METODO PROPIO PARA EL TRAIN-TEST SPLIT con los DATAFRAME y RANDOM \n",
    "\n",
    "  def get_trainset( self ):\n",
    "    return self.trainset\n",
    "  \n",
    "  def get_testset( self ):\n",
    "    return self.testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `Model`\n",
    "\n",
    "La clase `Model` está diseñada para encapsular un modelo de recomendación, proporcionando una interfaz simplificada para su evaluación mediante el uso de un generador de datos, que no es más que un objeto que contiene el conjunto de datos de entrenamiento y el conjunto de datos de prueba, y el cálculo de métricas de rendimiento específicas. A continuación, se detalla su funcionalidad:\n",
    "\n",
    "- Constructor (`__init__`)\n",
    "  - Inicializa la instancia con dos argumentos: `model` (objeto que representa el modelo de recomendación que se va a evaluar. Este modelo debe tener métodos `fit` para entrenamiento y `test` para generar predicciones) y `name` (cadena que indica el modelo, útil para referencias e informes de evaluación)\n",
    "  - Almacena estos dos argumentos como atributos de la instancia\n",
    "- Método `__str__`\n",
    "  - Proporciona una representación en forma de cadena del objeto `Model`, retornando una cadena que incluye el nombre del modelo. Esto es útil para imprimir información sobre el modelo de manera legible por humanos, facilitando la identificación del modelo cuando se imprime el objeto\n",
    "- Método `evaluate`\n",
    "  - Este método evalúa el rendimiento utilizando datos proporcionados por un objeto `DataGenerator`. \n",
    "    - Utiliza el conjunto de entrenamiento y prueba contenidos dentro de un objeto `DataGenerator` para entrenar el modelo y generar predicciones\n",
    "    - Primero, entrena el modelo con el conjunto de entrenamiento obtenido mediante `data.get_trainset()`\n",
    "    - Luego, utiliza el conjunto de prueba obtenido mediante `data.get_testset()` para generar predicciones. \n",
    "    - Calcula métricas de rendimiento específicas usando las predicciones generadas y los compara con los valores reales\n",
    "    - Retorna un diccionario con las métricas calculadas \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model: \n",
    "  def __init__(self, model, name) -> None:\n",
    "    self.model = model\n",
    "    self.name = name\n",
    "  \n",
    "  def __str__(self) -> str:\n",
    "    return f'Model: { self.name }'\n",
    "  \n",
    "  def evaluate ( self, data: DataGenerator ): \n",
    "    trainset = data.get_trainset ( )\n",
    "    testset = data.get_testset ( )\n",
    "\n",
    "    fit_model = self.model.fit ( trainset )\n",
    "    predictions = fit_model.test ( testset )\n",
    "\n",
    "    metrics = Metrics ( predictions ).compute_metrics( 'MAE', 'RMSE' )\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `Factory`\n",
    "\n",
    "La clase `Factory` en el código proporcionado es una clase de diseño que actúa como un contenedor y administrador para una colección de modelos (`Model`). Esta clase está diseñada para manejar operaciones relacionadas con los modelos que pueden usarse para sistemas de recomendación. Aquí hay una descripción detallada de lo que hace cada método dentro de esta clase:\n",
    "\n",
    "- Constructor `__init__(self, dataset) -> None`\n",
    "  - **Propósito**: Inicializa una instancia de la clase `Factory`.\n",
    "  - **Parámetros**:\n",
    "    - `dataset`: Un parámetro que se pasa al constructor para indicar el conjunto de datos con el cual se trabajarán los modelos.\n",
    "  - **Acciones**:\n",
    "    - Crea una instancia de `DataGenerator` pasando el `dataset` proporcionado y la asigna a `self.dataset`. Esto sugiere que `DataGenerator` es una clase responsable de preparar o formatear el conjunto de datos de alguna manera antes de su uso.\n",
    "    - Inicializa una lista vacía llamada `models`, destinada a almacenar instancias de modelos.\n",
    "\n",
    "- Método `add_model(self, model: Model) -> None`\n",
    "  - **Propósito**: Agrega un modelo a la lista de modelos manejados por la instancia de `Factory`.\n",
    "  - **Parámetros**:\n",
    "    - `model`: El modelo a agregar a la lista de modelos. Se espera que este argumento sea una instancia de la clase `Model` o una subclase de ella.\n",
    "  - **Acciones**:\n",
    "    - Añade el modelo pasado como argumento a la lista `self.models`.\n",
    "\n",
    "- Método `evaluate(self) -> dict`\n",
    "  - **Propósito**: Evalúa todos los modelos almacenados en la lista de modelos utilizando el mismo conjunto de datos.\n",
    "  - **Acciones**:\n",
    "    - Inicializa un diccionario vacío llamado `results`.\n",
    "    - Itera sobre cada modelo en `self.models`.\n",
    "    - Imprime un mensaje indicando que se está evaluando el modelo actual.\n",
    "    - Llama al método `evaluate` del modelo actual, pasándole el conjunto de datos `self.dataset`, y guarda el resultado en el diccionario `results` bajo la clave correspondiente al nombre del modelo.\n",
    "    - Devuelve el diccionario `results`, que contiene los resultados de la evaluación de todos los modelos.\n",
    "\n",
    "- Método `clean_models(self) -> None`\n",
    "  - **Propósito**: Limpia la lista de modelos, eliminando todos los modelos almacenados.\n",
    "  - **Acciones**:\n",
    "    - Asigna una lista vacía a `self.models`, efectivamente limpiando cualquier modelo previamente agregado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factory:\n",
    "  def __init__(self, dataset) -> None:\n",
    "    self.dataset = DataGenerator ( dataset )\n",
    "    self.models: list[ Model ] = [ ]\n",
    "  \n",
    "  def add_model ( self, model: Model ):\n",
    "    self.models.append ( model )\n",
    "  \n",
    "  def evaluate ( self ):\n",
    "    results = { }\n",
    "    for model in self.models:\n",
    "      print ( f'Evaluating { model.name }' )\n",
    "      results [ model.name ] = model.evaluate( self.dataset )\n",
    "\n",
    "  def clean_models ( self ):\n",
    "    self.models = [] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí se muestran algunas pruebas sobre las clases creadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVD\n",
      "MAE:  0.7402\n",
      "RMSE: 0.9411\n"
     ]
    }
   ],
   "source": [
    "model_svd = Model ( model=SVD(), name='SVD' )\n",
    "factory = Factory( loader.load_dataset( ) )\n",
    "\n",
    "factory.add_model( model_svd )\n",
    "factory.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Only\n",
      "Estimating biases using als...\n",
      "MAE:  0.7501\n",
      "RMSE: 0.9485\n"
     ]
    }
   ],
   "source": [
    "model_baseline = Model ( model=BaselineOnly(), name='Baseline Only' )\n",
    "factory = Factory( loader.load_dataset( ) )\n",
    "\n",
    "factory.add_model( model_baseline )\n",
    "factory.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `HybridModel`\n",
    "\n",
    "La clase `HybridModel` hereda de `AlgoBase` y está diseñada específicamente para sistemas de recomendación híbridos, combinando múltiples modelos individuales (`Model`) para generar recomendaciones basadas en pesos predefinidos. Este enfoque innovador permite integrar diversas técnicas de aprendizaje automático o modelos estadísticos, optimizando así la precisión y robustez de las recomendaciones generadas. A continuación, se detalla lo que cada componente de esta clase contribuye al funcionamiento general:\n",
    "\n",
    "- Constructor `__init__(self, models, weights, **kwargs)`\n",
    "  - **Propósito**: Inicializa una instancia de `HybridModel` en el contexto de un sistema de recomendación.\n",
    "  - **Parámetros**:\n",
    "    - `models`: Colección de modelos individuales (`Model`) seleccionados para colaborar en la generación de recomendaciones.\n",
    "    - `weights`: Lista de pesos asociados a cada modelo en `models`, que determinan su influencia relativa en la recomendación final.\n",
    "    - `**kwargs`: Parámetros adicionales que pueden ser pasados al constructor base `AlgoBase`, posiblemente incluyendo configuraciones específicas del sistema de recomendación.\n",
    "  - **Acciones**:\n",
    "    - Invoca el constructor de la clase base `AlgoBase` con cualquier argumento adicional proporcionado, asegurando la correcta inicialización dentro del marco de un sistema de recomendación.\n",
    "    - Asigna la lista de modelos a `self.models`, estableciendo la base para la integración de modelos.\n",
    "    - Asigna la lista de pesos a `self.weights`, configurando la estrategia de combinación ponderada utilizada para fusionar las predicciones de los modelos.\n",
    "\n",
    "- Método `fit(self, trainset)`\n",
    "  - **Propósito**: Entrena todos los modelos individuales contenidos en el modelo híbrido, preparándolos para la generación de recomendaciones.\n",
    "  - **Parámetros**:\n",
    "    - `trainset`: Conjunto de datos de entrenamiento utilizado para ajustar los modelos internos, asegurando que estén bien calibrados para el dominio de recomendación.\n",
    "  - **Acciones**:\n",
    "    - Ejecuta el método `fit` de la clase base `AlgoBase` para realizar cualquier configuración o ajuste inicial necesario, adaptándose al entorno del sistema de recomendación.\n",
    "    - Procesa cada modelo en `self.models`, entrenándolos individualmente con el conjunto de datos de entrenamiento `trainset`, afinando sus capacidades predictivas.\n",
    "    - Retorna `self`, facilitando la concatenación de operaciones, como la evaluación posterior o la generación de recomendaciones.\n",
    "\n",
    "- Método `estimate(self, user_id, item_id)`\n",
    "  - **Propósito**: Genera una recomendación para un usuario y un ítem específicos mediante la integración ponderada de las predicciones de los modelos individuales.\n",
    "  - **Parámetros**:\n",
    "    - `user_id`: Identificador único del usuario cuya preferencia se está estimando.\n",
    "    - `item_id`: Identificador único del ítem o elemento para el cual se está generando una recomendación.\n",
    "  - **Acciones**:\n",
    "    - Inicializa variables `scores` y `weight` a 0, preparándose para calcular la puntuación ponderada de recomendación.\n",
    "    - Itera sobre cada modelo en `self.models`, calcula la predicción de cada modelo para el par `(user_id, item_id)` multiplicada por su peso correspondiente, acumulando estos valores en `scores`.\n",
    "    - Suma el peso correspondiente a cada modelo a `weight`, construyendo la base para el cálculo de la media ponderada.\n",
    "    - Retorna la media ponderada de las predicciones de todos los modelos, dividiendo `scores` entre `weight`, produciendo una recomendación equilibrada que refleja la opinión de todos los modelos participantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel ( AlgoBase ):\n",
    "\n",
    "  def __init__ (self, models, weights, **kwargs):\n",
    "    super().__init__(**kwargs) \n",
    "    self.models: list[ Model ] = models\n",
    "    self.weights = weights\n",
    "  \n",
    "  def fit (self, trainset):\n",
    "    AlgoBase.fit ( self, trainset )\n",
    "    for model in self.models:\n",
    "      model.model.fit ( trainset )\n",
    "    return self\n",
    "  \n",
    "  def estimate ( self, user_id, item_id ):\n",
    "    scores = 0 \n",
    "    weight = 0\n",
    "    for i in range ( len( self.models ) ):\n",
    "      scores += self.models[i].model.predict ( user_id, item_id ).est * self.weights[i]\n",
    "      weight += self.weights[i]\n",
    "\n",
    "    return scores/weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se tiene un ejemplo básico del uso del modelo híbrido de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Hybrid: SVD - Baseline\n",
      "Estimating biases using als...\n",
      "MAE:  0.9949\n",
      "RMSE: 1.2280\n"
     ]
    }
   ],
   "source": [
    "models = [ \n",
    "  model_svd,\n",
    "  model_baseline\n",
    "]\n",
    "weights = [ \n",
    "  0.5,\n",
    "  0.5\n",
    "]\n",
    "\n",
    "hybrid = HybridModel ( models, weights )\n",
    "\n",
    "factory = Factory ( loader.load_dataset() )\n",
    "\n",
    "model = Model ( hybrid, 'Hybrid: SVD - Baseline' )\n",
    "factory.add_model ( model )\n",
    "\n",
    "factory.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "- Completar la clase de EDA\n",
    "- Mejorar los sistemas de recomendacion hibridos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
