{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las diferentes librerías que nos van a permitir trabajar con LLM, y esta es principalmente LangChain ... (descripción de LangChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "\n",
    "from surprise import ( \n",
    "  Dataset,\n",
    "  Reader,\n",
    "  accuracy, \n",
    "  SVD,\n",
    "  AlgoBase,\n",
    "  BaselineOnly,\n",
    "  NormalPredictor,\n",
    "  KNNBasic,\n",
    "  KNNWithMeans,\n",
    "  KNNBaseline,\n",
    "  KNNWithZScore,\n",
    "  SVDpp,\n",
    "  NMF,\n",
    "  SlopeOne,\n",
    "  CoClustering,\n",
    "  accuracy\n",
    ") \n",
    "\n",
    "from surprise.model_selection import (\n",
    "  train_test_split\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos métodos nos van a permitir trabajar con los modelos, pero antes es necesario las credenciales de Google API para poder usarlos. \n",
    "\n",
    "> El modelo que estaremos usando es `gemini-1.5-pro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_environment () -> None:\n",
    "  \"\"\"\n",
    "  Carga las variables de entorno necesarias para el funcionamiento del programa\n",
    "\n",
    "  Especificamente buscar las variables de entorno siguientes:\n",
    "  - `google_api_key` : clave de API de Google  \n",
    "  \"\"\"\n",
    "  \n",
    "  dotenv.load_dotenv()\n",
    "  os.environ.setdefault ( 'google_api_key', os.getenv('google_api_key') )\n",
    "\n",
    "def get_model() -> GoogleGenerativeAI:\n",
    "  \"\"\"\n",
    "  Inicializa y devuelve una instancia de GoogleGenerativeAI\n",
    "  con configuraciones predeterminadas \n",
    "\n",
    "  Contiene una funcion para cargar las credenciales de Google API \n",
    "  desde el entorno y crea una instancia de GoogleGenerativeAI\n",
    "  usando el modelo 'gemini-1.5-pro'\n",
    "\n",
    "  Args:\n",
    "\n",
    "  Returns:\n",
    "      GoogleGenerativeAI: instancia preconfigurada de GoogleGenerativeAI\n",
    "  \"\"\"\n",
    "\n",
    "  load_environment()\n",
    "  model = GoogleGenerativeAI(\n",
    "    model='models/gemini-1.5-pro-latest',\n",
    "    temperature=0.5\n",
    "  )\n",
    "  return model\n",
    "\n",
    "def get_embedding() -> GoogleGenerativeAIEmbeddings:\n",
    "  \"\"\"\n",
    "  Inicializa y devuelve una instancia de `GoogleGenerativeAIEmbeddings`\n",
    "\n",
    "  Esta funcion carga las credenciales de Google API desde el entorno y crea una instancia de `GoogleGenerativeAIEmbeddings`\n",
    "\n",
    "  Returns:\n",
    "      GoogleGenerativeAIEmbeddings: instancia preconfigurada del embedding model \n",
    "  \"\"\"\n",
    "\n",
    "  load_environment()\n",
    "  embedding = GoogleGenerativeAIEmbeddings(\n",
    "    model='models/embedding-001'\n",
    "  )\n",
    "  return embedding \n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definimos una función sencilla para poder probar el modelo de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_template_QA(question: str, k: int, model: GoogleGenerativeAI) -> str:\n",
    "  \"\"\"\n",
    "  Este metodo construye un template de chat que incluye instrucciones claras para el modelo de IA sobre como responder \n",
    "  a una pregunta especifica y sugerir posibles preguntas relacionadas. \n",
    "\n",
    "  Utiliza parametro `k` para especificar la cantidad de recomendaciones de preguntas debe incluir en su respuesta\n",
    "\n",
    "  Args:\n",
    "      question (str): la pregunta especifica que se desea que el modelo responda \n",
    "      k (int): cantidad de recomendaciones de preguntas relacionadas que se deben incluir en la respuesta \n",
    "      model (GoogleGenerativeAI): instancia del modelo de IA utilizado para generar respuesta\n",
    "\n",
    "  Returns:\n",
    "      result (str): respuesta generada por el modelo, incluyendo tanto la respuesta directa a la pregunta como las recomendaciones de preguntas relacionadas\n",
    "      \n",
    "  \"\"\"\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\" \n",
    "    Se lo mas simple posible para responder la siguiente pregunta \n",
    "    y da algunas recomendaciones a preguntas que se parezcan al tema de la pregunta\n",
    "\n",
    "    Solo devuelve la respuesta. Seguido de las preguntas. Ejemplo:\n",
    "    \n",
    "    Answer\n",
    "\n",
    "    Posibles preguntas:\n",
    "    - Pregunta sugerida 1\n",
    "    - Pregunta sugerida 2\n",
    "    - Pregunta sugerida 3  \n",
    "\n",
    "    El numero de preguntas que sugieres debe estar fijado al siguiente numero:\n",
    "    Numero de recomendaciones: {k}\n",
    "\n",
    "    Q: {question}\n",
    "    A: \n",
    "    \"\"\"\n",
    "  )\n",
    "  \n",
    "  chain = prompt | model \n",
    "  result = chain.invoke(\n",
    "    {\n",
    "      \"question\": question,\n",
    "      \"k\": k\n",
    "    })\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogleGenerativeAI(model='models/gemini-1.5-pro-latest', temperature=0.5, client=genai.GenerativeModel(\n",
       "    model_name='models/gemini-1.5-pro-latest',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=None,\n",
       "    system_instruction=None,\n",
       "))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model = get_model ( )\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un sistema de recomendación sugiere elementos a los usuarios. Los elementos pueden ser cualquier cosa, como películas, libros, productos, etc. \n",
      "\n",
      "Posibles preguntas:\n",
      "- ¿Cómo funcionan los sistemas de recomendación?\n",
      "- ¿Cuáles son los diferentes tipos de sistemas de recomendación?\n",
      "- ¿Cuáles son las ventajas de usar un sistema de recomendación?\n",
      "- ¿Cuáles son algunos ejemplos de sistemas de recomendación en el mundo real?\n",
      "- ¿Cuáles son algunos de los desafíos en la construcción de sistemas de recomendación? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ( prompt_template_QA ( question='Que es un sistema de recomendacion', k=5, model=llm_model ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a definir un punto importante para formar un *Sistema de Recomendación usando LLM*: la característica de Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader: \n",
    "  \n",
    "  def __init__(self, data_path: str, item_path: str, user_path: str) -> None:\n",
    "    \n",
    "    current = os.getcwd () [ 0 : os.getcwd ().rfind( '\\\\' ) ]\n",
    "    self.DATA_PATH = current + data_path\n",
    "    self.ITEM_PATH = current + item_path\n",
    "    self.USER_PATH = current + user_path\n",
    "\n",
    "    self.data_set = self.load_set ( 'DATA' )\n",
    "    self.item_set = self.load_set ( 'ITEM' )\n",
    "    self.user_set = self.load_set ( 'USER' )\n",
    "\n",
    "  def load_set (self, name: str ) -> pd.DataFrame:\n",
    "\n",
    "    if name == 'DATA':\n",
    "      columns = [ 'userID', 'itemID', 'rating', 'timestamp' ]\n",
    "      df = pd.read_csv ( \n",
    "        self.DATA_PATH, \n",
    "        names=columns, \n",
    "        sep='\\t', \n",
    "        encoding='latin-1', \n",
    "        skipinitialspace=True \n",
    "      )\n",
    "      df = df.drop ( columns= [ 'timestamp' ] )\n",
    "      return df\n",
    "  \n",
    "    if name == 'USER':\n",
    "      columns = [ 'userID', 'age', 'gender', 'occupation', 'zipCode' ]\n",
    "      df = pd.read_csv ( \n",
    "        self.USER_PATH, \n",
    "        names=columns, \n",
    "        sep='|', \n",
    "        encoding='latin-1', \n",
    "        skipinitialspace=True \n",
    "      )\n",
    "      df = df.drop ( columns= [ 'zipCode' ] )\n",
    "      return df\n",
    "  \n",
    "    if name == 'ITEM':\n",
    "      columns = [ \n",
    "        'itemID', \n",
    "        'name', \n",
    "        'releaseDate', \n",
    "        'videoReleaseDate', \n",
    "        'IMDbURL', \n",
    "        'gender_unknown', \n",
    "        'gender_action', \n",
    "        'gender_adventure', \n",
    "        'gender_animation', \n",
    "        'gender_children', \n",
    "        'gender_comedy',\n",
    "        'gender_crime',\n",
    "        'gender_documentary',\n",
    "        'gender_drama',\n",
    "        'gender_fantasy',\n",
    "        'gender_film_noir',\n",
    "        'gender_horror',\n",
    "        'gender_musical',\n",
    "        'gender_mystery',\n",
    "        'gender_romance',\n",
    "        'gender_scifi',\n",
    "        'gender_thriller',\n",
    "        'gender_war',\n",
    "        'gender_western',\n",
    "      ]\n",
    "      df = pd.read_csv ( \n",
    "        self.ITEM_PATH, \n",
    "        names=columns, \n",
    "        sep='|', \n",
    "        encoding='latin-1', \n",
    "        skipinitialspace=True \n",
    "      )\n",
    "      df = df.drop ( columns= [ 'videoReleaseDate', 'IMDbURL' ] )\n",
    "      return df\n",
    "\n",
    "  def load_dataset ( self ) -> Dataset:\n",
    "    reader = Reader ( rating_scale= ( 1,5 ) )\n",
    "    data = Dataset.load_from_df ( self.data_set [ [ 'userID', 'itemID', 'rating' ] ], reader )\n",
    "    return data\n",
    "\n",
    "  def get_user_by_id ( self, id: int ):\n",
    "    info = self.user_set.loc [ self.user_set[ 'userID' ] == id ]\n",
    "    return info[ [ 'userID', 'age', 'gender', 'occupation' ] ].iloc[0].to_dict()\n",
    "\n",
    "  def get_item_by_id ( self, id: int ):\n",
    "    info = self.item_set.loc [ self.item_set[ 'itemID' ] == id ]\n",
    "    return info[ [ \n",
    "      'itemID', \n",
    "      'name', \n",
    "      'releaseDate', \n",
    "      'gender_unknown', \n",
    "      'gender_action', \n",
    "      'gender_adventure', \n",
    "      'gender_animation', \n",
    "      'gender_children', \n",
    "      'gender_comedy',\n",
    "      'gender_crime',\n",
    "      'gender_documentary',\n",
    "      'gender_drama',\n",
    "      'gender_fantasy',\n",
    "      'gender_film_noir',\n",
    "      'gender_horror',\n",
    "      'gender_musical',\n",
    "      'gender_mystery',\n",
    "      'gender_romance',\n",
    "      'gender_scifi',\n",
    "      'gender_thriller',\n",
    "      'gender_war',\n",
    "      'gender_western', ] ].iloc[0].to_dict()\n",
    "\n",
    "  def get_rating_by_ids ( self, user_id: int, item_id: int ):\n",
    "    try:\n",
    "      rating = self.data_set.loc [ self.data_set[ 'userID' ] == user_id ].loc [ self.data_set[ 'itemID' ] == item_id ]\n",
    "      return ( rating.iloc[0]['rating'], True )\n",
    "    except:\n",
    "      # Failed to retrieve the rating\n",
    "      return ( -1, False )\n",
    "\n",
    "  def get_ratings_by_name_id ( self, column_name: str, id: int ):\n",
    "    filtered_data = self.data_set.loc [ self.data_set[ column_name ] == id ]\n",
    "    return filtered_data [ [ 'userID', 'itemID', 'rating' ] ]\n",
    "  \n",
    "\n",
    "\n",
    "DATA_PATH = '\\\\dataset\\\\data.csv'\n",
    "ITEM_PATH = '\\\\dataset\\\\item.csv'\n",
    "USER_PATH = '\\\\dataset\\\\user.csv'\n",
    "\n",
    "loader = DataLoader( \n",
    "  data_path=DATA_PATH,\n",
    "  item_path=ITEM_PATH,\n",
    "  user_path=USER_PATH \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userID  itemID  rating\n",
       "0         196     242       3\n",
       "1         186     302       3\n",
       "2          22     377       1\n",
       "3         244      51       2\n",
       "4         166     346       1\n",
       "...       ...     ...     ...\n",
       "99995     880     476       3\n",
       "99996     716     204       5\n",
       "99997     276    1090       1\n",
       "99998      13     225       2\n",
       "99999      12     203       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>name</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>gender_unknown</th>\n",
       "      <th>gender_action</th>\n",
       "      <th>gender_adventure</th>\n",
       "      <th>gender_animation</th>\n",
       "      <th>gender_children</th>\n",
       "      <th>gender_comedy</th>\n",
       "      <th>gender_crime</th>\n",
       "      <th>...</th>\n",
       "      <th>gender_fantasy</th>\n",
       "      <th>gender_film_noir</th>\n",
       "      <th>gender_horror</th>\n",
       "      <th>gender_musical</th>\n",
       "      <th>gender_mystery</th>\n",
       "      <th>gender_romance</th>\n",
       "      <th>gender_scifi</th>\n",
       "      <th>gender_thriller</th>\n",
       "      <th>gender_war</th>\n",
       "      <th>gender_western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678</td>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679</td>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "      <td>06-Feb-1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "      <td>01-Jan-1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "      <td>08-Mar-1996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      itemID                                       name  releaseDate  \\\n",
       "0          1                           Toy Story (1995)  01-Jan-1995   \n",
       "1          2                           GoldenEye (1995)  01-Jan-1995   \n",
       "2          3                          Four Rooms (1995)  01-Jan-1995   \n",
       "3          4                          Get Shorty (1995)  01-Jan-1995   \n",
       "4          5                             Copycat (1995)  01-Jan-1995   \n",
       "...      ...                                        ...          ...   \n",
       "1677    1678                          Mat' i syn (1997)  06-Feb-1998   \n",
       "1678    1679                           B. Monkey (1998)  06-Feb-1998   \n",
       "1679    1680                       Sliding Doors (1998)  01-Jan-1998   \n",
       "1680    1681                        You So Crazy (1994)  01-Jan-1994   \n",
       "1681    1682  Scream of Stone (Schrei aus Stein) (1991)  08-Mar-1996   \n",
       "\n",
       "      gender_unknown  gender_action  gender_adventure  gender_animation  \\\n",
       "0                  0              0                 0                 1   \n",
       "1                  0              1                 1                 0   \n",
       "2                  0              0                 0                 0   \n",
       "3                  0              1                 0                 0   \n",
       "4                  0              0                 0                 0   \n",
       "...              ...            ...               ...               ...   \n",
       "1677               0              0                 0                 0   \n",
       "1678               0              0                 0                 0   \n",
       "1679               0              0                 0                 0   \n",
       "1680               0              0                 0                 0   \n",
       "1681               0              0                 0                 0   \n",
       "\n",
       "      gender_children  gender_comedy  gender_crime  ...  gender_fantasy  \\\n",
       "0                   1              1             0  ...               0   \n",
       "1                   0              0             0  ...               0   \n",
       "2                   0              0             0  ...               0   \n",
       "3                   0              1             0  ...               0   \n",
       "4                   0              0             1  ...               0   \n",
       "...               ...            ...           ...  ...             ...   \n",
       "1677                0              0             0  ...               0   \n",
       "1678                0              0             0  ...               0   \n",
       "1679                0              0             0  ...               0   \n",
       "1680                0              1             0  ...               0   \n",
       "1681                0              0             0  ...               0   \n",
       "\n",
       "      gender_film_noir  gender_horror  gender_musical  gender_mystery  \\\n",
       "0                    0              0               0               0   \n",
       "1                    0              0               0               0   \n",
       "2                    0              0               0               0   \n",
       "3                    0              0               0               0   \n",
       "4                    0              0               0               0   \n",
       "...                ...            ...             ...             ...   \n",
       "1677                 0              0               0               0   \n",
       "1678                 0              0               0               0   \n",
       "1679                 0              0               0               0   \n",
       "1680                 0              0               0               0   \n",
       "1681                 0              0               0               0   \n",
       "\n",
       "      gender_romance  gender_scifi  gender_thriller  gender_war  \\\n",
       "0                  0             0                0           0   \n",
       "1                  0             0                1           0   \n",
       "2                  0             0                1           0   \n",
       "3                  0             0                0           0   \n",
       "4                  0             0                1           0   \n",
       "...              ...           ...              ...         ...   \n",
       "1677               0             0                0           0   \n",
       "1678               1             0                1           0   \n",
       "1679               1             0                0           0   \n",
       "1680               0             0                0           0   \n",
       "1681               0             0                0           0   \n",
       "\n",
       "      gender_western  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1677               0  \n",
       "1678               0  \n",
       "1679               0  \n",
       "1680               0  \n",
       "1681               0  \n",
       "\n",
       "[1682 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.item_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID  age gender     occupation\n",
       "0         1   24      M     technician\n",
       "1         2   53      F          other\n",
       "2         3   23      M         writer\n",
       "3         4   24      M     technician\n",
       "4         5   33      F          other\n",
       "..      ...  ...    ...            ...\n",
       "938     939   26      F        student\n",
       "939     940   32      M  administrator\n",
       "940     941   20      M        student\n",
       "941     942   48      F      librarian\n",
       "942     943   22      M        student\n",
       "\n",
       "[943 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.user_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones utiles para esta caracteristica\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = get_model()\n",
    "embedding = get_embedding()\n",
    "\n",
    "current = os.getcwd()\n",
    "doc_dir = '\\\\database\\\\doc'\n",
    "faiss_dir = '\\\\database\\\\faiss'\n",
    "\n",
    "DATA_PATH = current + doc_dir\n",
    "FAISS_PATH = current + faiss_dir\n",
    "\n",
    "dir = os.listdir(DATA_PATH)\n",
    "\n",
    "\n",
    "\n",
    "def search_docs() -> list[str]:\n",
    "  \"\"\"\n",
    "  Busca todos los documentos disponibles en el directorio especificado y retorna sus rutas completas\n",
    "\n",
    "  Este metodo recorre el directorio establecido en la variable global 'DATA_PATH', buscando todos los archivos presentes y retornando sus rutas completas como una lista de cadenas\n",
    "  \n",
    "  Nota: Las rutas devueltas son relativas al directorio actual del proyecto\n",
    "\n",
    "  Returns:\n",
    "      list[str]: una lista de cadenas donde cada elemento es la ruta completa de un documento encontrado en el directorio especificado\n",
    "  \"\"\"\n",
    "  docs_dir = os.listdir(DATA_PATH)\n",
    "  docs_dir = [DATA_PATH + '\\\\' + item for item in docs_dir]\n",
    "  return docs_dir\n",
    "\n",
    "\n",
    "\n",
    "def load_contents(docs_dir: list[str]) -> list[str]:\n",
    "  \"\"\"\n",
    "  Lee y retorna el contenido de todos los documentos especificados por sus rutas.\n",
    "\n",
    "  Este metodo itera sobre cada ruta del documento proporcionada en la lista 'docs_dir', lee el contenido de cada uno de estos archivos y los agrega a una lista, la cual luego retorna\n",
    "\n",
    "  Nota: Los archivos deben estar en formato de texto plano para poder ser leidos correctamente por este metodo\n",
    "\n",
    "  Args:\n",
    "      docs_dir (list[str]): Lista de rutas de directorios completas a los documentos cuyo contenido se desea leer\n",
    "\n",
    "  Returns:\n",
    "      list[str]: Lista de cadenas donde cada elemento es el contenido leido de un documento correspondiente a las rutas proporcionadas\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "  def load_content(doc_dir: str):\n",
    "    content = ''\n",
    "    with open(doc_dir, 'r', encoding='ISO-8859-1') as file:\n",
    "      content = file.read()\n",
    "    return content  \n",
    "  \n",
    "  docs_content = [load_content(doc_dir=doc_dir) for doc_dir in docs_dir]\n",
    "  return docs_content \n",
    "\n",
    "\n",
    "\n",
    "def chunkenizer(content: str) -> List[Document]:\n",
    "  \"\"\"\n",
    "  Este metodo se encarga de separar en chunks el contenido de un documento. Esta fragmentacion la hace usando un metodo recursivo llamado `RecursiveCharacterTextSplitter` con valores predeterminados\n",
    "\n",
    "  Args:\n",
    "      content (str): contenido de un documento correspondiente\n",
    "\n",
    "  Returns:\n",
    "      List[Document]: lista de chunks del documento de entrada \n",
    "  \"\"\"\n",
    "\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1024,\n",
    "    chunk_overlap = 204,\n",
    "    length_function = len\n",
    "  )\n",
    "  chunks = text_splitter.create_documents([content])\n",
    "  return chunks\n",
    "\n",
    "\n",
    "\n",
    "def create_chunks() -> List[Document]:\n",
    "  \"\"\"\n",
    "  Divide el contenido de todos los documentos encontrados en chunks. \n",
    "\n",
    "  Este metodo primero busca todos los documentos disponibles en el directorio especificado, \n",
    "  luego lee y retorna el contenido de estos documentos. Posteriormente, divide el contenido de cada documento\n",
    "  en chunks utilizando un metodo especifico de division de texto, y retorna una lista de objetos `Document`, \n",
    "  donde cada objeto representa un chunk del contenido original\n",
    "\n",
    "  Returns:\n",
    "      List[Document]: Una lista de objetos Document, donde cada objeto representa un chunk del contenido de un documento\n",
    "  \"\"\"\n",
    "\n",
    "  docs_dir = search_docs()\n",
    "  docs_content = load_contents(docs_dir)\n",
    "  chunks: List[Document] = []\n",
    "  for doc_content in docs_content:\n",
    "    \n",
    "    document = Document(page_content=doc_content)\n",
    "    chunks.append(document)\n",
    "    \n",
    "    \"\"\" \n",
    "    # CHUNK THE DOCUMENTS\n",
    "    for item in chunkenizer(doc_content):\n",
    "      chunks.append(item)\n",
    "    \"\"\"\n",
    "    \n",
    "  return chunks\n",
    "\n",
    "\n",
    "\n",
    "class Faiss_Vectorstore:\n",
    "\n",
    "\n",
    "\n",
    "  def __init__(self, load: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Inicializa una instancia de `FAISS_VECTORSTORE` para manejar y buscar en una base de datos vectorial de FAISS\n",
    "\n",
    "    Este constructor permite opcionalmente cargar la base de datos vectorial existente si se pasa `True` al parametro `load`. \n",
    "    Si `load` es `False` (valor predeterminado), se crea una nueva base de datos vectorial con los documentos proporcionados\n",
    "\n",
    "    Args:\n",
    "        load (bool, optional): Indica si se debe cargar la base de datos vectorial. Defaults to False.\n",
    "    \"\"\"\n",
    "    if load: \n",
    "      self.__vs = FAISS.load_local(\n",
    "        folder_path=FAISS_PATH, \n",
    "        embeddings=embedding,\n",
    "        allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "      chunks = create_chunks()\n",
    "      \n",
    "      \"\"\" \n",
    "      ERROR POR LA CANTIDAD DE ELEMENTOS DE CHUNKS (debe ser por eso)\n",
    "      self.__vs = FAISS.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embedding\n",
    "      )\n",
    "      \"\"\"\n",
    "\n",
    "      self.__vs = FAISS.from_documents(\n",
    "        documents=chunks[0:100], \n",
    "        embedding=embedding)\n",
    "\n",
    "      i = 101\n",
    "      while True:\n",
    "        if i >= len(chunks):\n",
    "          break\n",
    "        if i + 99 >= len(chunks):\n",
    "          extension = FAISS.from_documents(\n",
    "            documents=chunks[i:len(chunks)],\n",
    "            embedding=embedding\n",
    "          )\n",
    "          self.__vs.merge_from(extension)\n",
    "          break\n",
    "        extension = FAISS.from_documents(\n",
    "          documents=chunks[i:i+99],\n",
    "          embedding=embedding\n",
    "        )\n",
    "        i=i+100\n",
    "      self.__vs.save_local(FAISS_PATH)\n",
    "\n",
    "\n",
    "\n",
    "  def similarity_search(self, query: str, k: int = 3) -> list[str]:\n",
    "    \"\"\"\n",
    "    Realiza una busqueda de similaridad en la base de datos vectorial utilizando una consulta \n",
    "\n",
    "    Este metodo busca en los documentos, los similares a la consulta proporcionada, utilizan el numero de resultados `k`\n",
    "\n",
    "    Args:\n",
    "        query (str): la consulta de texto para realizar la busqueda de similitud\n",
    "        k (int, optional): numero de resultados similares a retornar. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: una lista de cadenas donde cada elemento es el contenido de un documento encontrado que es similar a la consulta\n",
    "    \"\"\"\n",
    "    if not k > 0:\n",
    "      raise Exception(\"k no puede ser negativo ni 0\")\n",
    "    results = self.__vs.similarity_search(query=query, k=k)\n",
    "    results_content = [result.page_content for result in results]\n",
    "    return results_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistory:\n",
    "  \n",
    "  def __init__(self, with_vectorstore: bool = True) -> None:\n",
    "    self.model: GoogleGenerativeAI = get_model()\n",
    "    self.embedding: GoogleGenerativeAIEmbeddings = get_embedding()\n",
    "    self.chat: list = []\n",
    "    self.prompt = \"\"\"\n",
    "    Eres un asistente, capaz de responder detalladamente las respuestas que se te hagan\n",
    "    Tambien debes tener conocimiento sobre la conversacion que tengas con el usuario\n",
    "    \"\"\"\n",
    "    if with_vectorstore: self.vectorstore = Faiss_Vectorstore(load=True)  \n",
    "\n",
    "\n",
    "\n",
    "  def make_chain(self) -> None:\n",
    "    self.prompt = ChatPromptTemplate.from_messages([\n",
    "      ('system', f'{self.prompt}'),\n",
    "      MessagesPlaceholder(variable_name='chat'),\n",
    "      ('human', '{input}')\n",
    "    ])\n",
    "    self.chain = self.prompt | self.model\n",
    "\n",
    "\n",
    "\n",
    "  def clean_history(self) -> None:\n",
    "    self.chat: list = []\n",
    "\n",
    "\n",
    "\n",
    "  def send_processed_query(self, query: str) -> str:\n",
    "    response = self.chain.invoke({'input':query, 'chat':self.chat})\n",
    "    self.chat.append( HumanMessage(content=query) )\n",
    "    self.chat.append( AIMessage(content=response) )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ejecutar un poco de pruebas sobre el LLM con Chat History para ver sus capacidad para recordar y aprender de la conversación que se tenga con este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPROBAR QUE SE CREE LA BASE DE DATOS VECTORIAL CORRECTAMENTE \n",
    "\n",
    "def test__create_vectorstore():\n",
    "  Faiss_Vectorstore()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPROBAR QUE LA BUSQUEDA POR SIMILITUD QUE TRAE LA CLASE `FAISS_VECTORE` FUNCIONE\n",
    "\n",
    "def testing_load_and_query_something():\n",
    "  vs = Faiss_Vectorstore(load=True)\n",
    "  result = vs.similarity_search(query='que es la apologetica', k=10)\n",
    "  for item in result:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
